{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulBarriere/TSE-NBSVM/blob/main/Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4x_dUR_AUoA"
      },
      "source": [
        "# Report Project NBSVM (Naive-Bayes Support Vector Machines)\n",
        "Nicolas Le Gall and Paul Barriere Master 2 students in Econometrics and Statistics at Toulouse School of Economics. \n",
        "\n",
        "The aim of this report is to illustrate the functions we built to implement the NB-SVM modelisation method introduced in *Baselines and Bigrams: Simple, Good Sentiment and Topic Classification*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI7_74dD4G6d",
        "outputId": "79ca8122-961d-436e-845f-a91dafff2d0c"
      },
      "source": [
        "!git clone https://@github.com/PaulBarriere/TSE-NBSVM.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TSE-NBSVM'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 101 (delta 46), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (101/101), 168.25 KiB | 3.00 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JEO0iIbWPmn"
      },
      "source": [
        "# 0. Execute all the .py files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwGDw34vWcmi"
      },
      "source": [
        "*This step allows to import and downloads all the packages we need and to run the functions we created. It avoids to have an overweighted notebook. In the end this notebook is really easy looking and confirtable for the users.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wumjjwGfzqsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479d1333-7bfd-4c68-9d4d-6ebac40efb27"
      },
      "source": [
        "# Functions for the data\n",
        "%run TSE-NBSVM/Functions_Import_Data.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3SqhIszzy92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6ab355-d4b3-46b8-b328-25c6cf649f38"
      },
      "source": [
        "# Functions NBSVM\n",
        "%run TSE-NBSVM/Functions_NBSVM.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WhRpzaswIM-"
      },
      "source": [
        "Now that we imported the functions and packages let's have a look at the data we choose to illustrate our work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb4vCAVSW1of"
      },
      "source": [
        "# 1. Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj6E9QblwlDN"
      },
      "source": [
        "liste_fichier = ['Nokia_6610.txt', 'Apex_AD2600_Progressive_scan_DVD_player.txt', \n",
        "                 'Canon_G3.txt', 'Creative_Labs_Nomad_Jukebox_Zen_Xtra_40GB.txt', \n",
        "                 'Nikon_coolpix_4300.txt']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L71STOyLW5-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086ff791-f6db-4a94-f502-47eed3311abe"
      },
      "source": [
        "Nokia_6610_x, Nokia_6610_y, Apex_AD2600_Progressive_scan_DVD_player_x, Apex_AD2600_Progressive_scan_DVD_player_y, Canon_G3_x, Canon_G3_y, Creative_Labs_Nomad_Jukebox_Zen_Xtra_40GB_x, Creative_Labs_Nomad_Jukebox_Zen_Xtra_40GB_y, Nikon_coolpix_4300_x, Nikon_coolpix_4300_y = import_all_data(liste_fichier)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews for this product :36\n",
            "Number of reviews for this product :97\n",
            "Number of reviews for this product :42\n",
            "Number of reviews for this product :91\n",
            "Number of reviews for this product :30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lun5f3m7XbPY"
      },
      "source": [
        "There are several product and it could be interesting to look if we can mix them for example. We have imported and cleaned our data with the previous function (import_all_data), let us have a look at how it look with the first review of Apex_AD2600_Progressive_scan_DVD_player and its grade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "X03N7YwQ1ipC",
        "outputId": "6c06cac5-70d1-405b-8350-5397e458d21d"
      },
      "source": [
        "Apex_AD2600_Progressive_scan_DVD_player_x[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bought apex dvd players player p play everything died shortly getting back using player nice machines consider quality pretty low'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipZ-i8sj15TP",
        "outputId": "08f6cd86-131f-4192-871d-efed7f510681"
      },
      "source": [
        "Apex_AD2600_Progressive_scan_DVD_player_y[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYztoGyq6E-z"
      },
      "source": [
        "The samples are different. Creative_Labs_Nomad_Jukebox_Zen_Xtra_40GB has much bigger reviews for example than Apex_AD2600_Progressive_scan_DVD_player."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCrTb2YC2RB5",
        "outputId": "51e9195a-4aff-4a7f-fc13-311ea7800a0d"
      },
      "source": [
        "count = 0\n",
        "for i in [Nokia_6610_x, Apex_AD2600_Progressive_scan_DVD_player_x, Canon_G3_x, Creative_Labs_Nomad_Jukebox_Zen_Xtra_40GB_x, Nikon_coolpix_4300_x]:\n",
        "  avg_mean = round(np.mean([len(i[j]) for j in range(len(i))]))\n",
        "  avg_std = round(np.std([len(i[j]) for j in range(len(i))]))\n",
        "  print('The average number of character in {} is {}. And the standard deviation is {}'.format(liste_fichier[count], avg_mean, avg_std))\n",
        "  count+=1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average number of character in Nokia_6610.txt is 779. And the standard deviation is 648\n",
            "The average number of character in Apex_AD2600_Progressive_scan_DVD_player.txt is 336. And the standard deviation is 259\n",
            "The average number of character in Canon_G3.txt is 822. And the standard deviation is 703\n",
            "The average number of character in Creative_Labs_Nomad_Jukebox_Zen_Xtra_40GB.txt is 1031. And the standard deviation is 868\n",
            "The average number of character in Nikon_coolpix_4300.txt is 656. And the standard deviation is 486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8HdQ2im6fpI"
      },
      "source": [
        "Let's perform the modelisation on Apex_AD2600_Progressive_scan_DVD_player first. We divide it into a test and train set with 70% in the train set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkr8MH0066ug"
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(Apex_AD2600_Progressive_scan_DVD_player_x, \n",
        "                                                    Apex_AD2600_Progressive_scan_DVD_player_y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=2000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2zRfRd0Xul8"
      },
      "source": [
        "# 3. Naive Bayes: \n",
        "\n",
        "### Explonation and illustration of the model\n",
        "This model as explained in the paper uses a vector $V$ which is the list of vocabulary present in the train sample. We can choose if we want unigrams, bigrams, or more. We choose here to have both unigrams and bigrams.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbsyse3nXxMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a6dacd-aabf-4799-972e-f95d99ce2508"
      },
      "source": [
        "''' Illustration on this example with 10 random elements of vector V '''\n",
        "V, F, vectorization = vectorize(Train_x_sample = train_x, ngrams=(1,2))\n",
        "random.sample(V,10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['multiformat',\n",
              " 'occasionally lip',\n",
              " 'known problem',\n",
              " 'past',\n",
              " 'sharp',\n",
              " 'name',\n",
              " 'dvd dvd',\n",
              " 'mixed bag',\n",
              " 'reads quietly',\n",
              " 'always']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwgpeV9y9YD0"
      },
      "source": [
        "Then we have a matrix $F$ which columns are reviews and rows are number of elements of the vector $V$ in this review. So $F_{i,j}$ is the number of time the element i of the vector $V$ ($V_i$) is in the review j."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN1CdS8l-Pdi",
        "outputId": "525ebae2-f2e8-4fa8-a058-a37537726c55"
      },
      "source": [
        "''' Illustration on this example with first 5 columns of the matrix F (ie the \n",
        "5 first reviews and 20 lines of V '''\n",
        "\n",
        "F[30:50,:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Jeugl0-6T4"
      },
      "source": [
        "Then we have re-write the train sample in the form of a matrix of integers. The idea is now to compute the log-count ratio vector $R$ which is a vector of size len($V$). In order to compute $R$ we defined $P$ and $Q$ two vectors:\n",
        "* $P = \\alpha + \\sum_{i:y(i)=1} f^{(i)}$ with smoothing parameter $\\alpha$.\n",
        "* $Q = \\alpha + \\sum_{i:y(i)=-1} f^{(i)}$ with smoothing parameter $\\alpha$ (the same).\n",
        "\n",
        "$f^{(i)}$ is a vector of occurences of V in the review i. So P and Q are basically sum of columns of F (positive review for P and negative for Q).\n",
        "\n",
        "\n",
        "\n",
        "Then we define R by : \n",
        "$R = log(\\frac{P/\\| P\\|_1}{Q/\\| Q\\|_1})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ1hY9-Q-yD1",
        "outputId": "298e1e1f-f42d-4040-fd02-11e9a9ff9691"
      },
      "source": [
        "# We implemented a function to compute directly R:\n",
        "R = get_R(alpha = .1,Train_y_sample = train_y, F = F)\n",
        "R"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.37430794, -0.37430794, -2.77220321, ..., -0.37430794,\n",
              "       -0.37430794, -0.37430794])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dePZmyhCFnj1"
      },
      "source": [
        "This log-count matrix is the W matrix in the model explained in the paper:\n",
        "\n",
        "$y^{(k)} = sign(W^T X^{(k)} + b)$. Where :\n",
        "* $y^{(k)}$ is the prediction of the $k^{th}$ review\n",
        "* $W$ is the log count ratio ($R$) \n",
        "* $X^{(k)}$ is the $k^{th}$ review expressed in a vector of occurences of terms in V. \n",
        "*  $b$ is defined as follow: $b = log(N+~/~N−)$ where $N+$ is the number of positive review.\n",
        "\n",
        "So in order to predict a new sample we have to transform the test sample in a vector of V. So the matrix $Sample$ defined below is for $(i,j)$, $Sample_{(i,j)}~=~$number of time the element $i$ of the vector $V$ is in the review $j$ of test_x. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m4fdQSVA5aN",
        "outputId": "57c9ae9b-0cd4-4adb-d4ed-633aee6db1f8"
      },
      "source": [
        "sample = vectorization.transform(test_x).toarray().T\n",
        "# We do have :\n",
        "len(sample) == len(V)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9p7689gHhaf",
        "outputId": "63e0ea2d-7197-4242-f7e2-6b3cdd6ae67b"
      },
      "source": [
        "# And the number of columns is equal to number of test_x reviews:\n",
        "len(sample[0]) == len(test_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xOB6AuvIL71",
        "outputId": "c42a3202-cf99-48c0-c939-1b9e136d946c"
      },
      "source": [
        "sample"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXxExDQYISuX"
      },
      "source": [
        "Then to compute the prediction we apply the model and compute the product of $W^T.Sample + B$ where $B$ is defined as follow: $b = log(N+~/~N−)$ where $N+$ is the number of positive review.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mc5DE3XJFzS",
        "outputId": "f555034b-409b-440a-c44a-8db620564eb7"
      },
      "source": [
        "nb_neg = len([i for i, value in enumerate(train_y) if value == -1])\n",
        "nb_pos = len([i for i, value in enumerate(train_y) if value == 1])\n",
        "B = np.log(nb_pos/nb_neg)\n",
        "B"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3930425881096072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEX75lZrJP5S"
      },
      "source": [
        "We compute the product of $W^T$ and $Sample$ and apply minus B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2KKVKfrJPP3",
        "outputId": "faa8a658-f4ed-42d8-a851-bba6ace3f765"
      },
      "source": [
        "np.dot(R.T,sample) + B"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.70671658e+01,  5.09275942e+00,  4.40375276e+01,  4.35835184e-02,\n",
              "       -4.39010698e+01, -1.57494584e+01, -3.59975026e+01,  1.91536760e+01,\n",
              "        2.61759522e+01,  5.55536435e+00,  1.32167523e+01,  2.03342614e+01,\n",
              "       -2.04423485e+00,  4.20131554e+00,  7.30995692e+01,  2.33973428e-01,\n",
              "        6.21047019e-01,  2.86168938e+01, -1.92038291e+00,  4.94957117e+00,\n",
              "       -1.14154734e+01,  7.90024495e+00, -2.18059360e+01, -2.25150590e+00,\n",
              "        7.36509311e-01,  5.52234153e+00,  1.00315615e+01,  1.09743408e+00,\n",
              "        1.46057979e+01,  2.47714136e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv5arfrLKQld"
      },
      "source": [
        "And now we take the sign of this expression to have the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1j8A-1LJuKs",
        "outputId": "81292527-6bc4-4bc0-ad2f-82c48887364d"
      },
      "source": [
        "np.sign(np.dot(R.T,sample) + B)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
              "        1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,\n",
              "        1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh7jWTYr_FRd"
      },
      "source": [
        "### Functions implemented\n",
        "The previous cells were to show step by step how to construct the model as explained in the paper. But we created a function which directly compute every vectors and matrix needed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrvgSnX__Wm_"
      },
      "source": [
        "W, B, binarized, vectorization = MNB_fit_model(Train_x_sample = train_x, \n",
        "                                              Train_y_sample = train_y,\n",
        "                                              ngrams = (1,2), \n",
        "                                              alpha = .1, \n",
        "                                              binarized=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4KlkZQOAB-j",
        "outputId": "feec5373-8061-451f-a222-943abdb6fa2f"
      },
      "source": [
        "pred = predict(binarized,W,B,vectorization,test_x)\n",
        "pred"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
              "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,\n",
              "        1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krj5GEMoAF91"
      },
      "source": [
        "We can have a look to the accuracy of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHzlWwgoAMQS",
        "outputId": "51aab228-5775-4d61-989a-86fe1efdabad"
      },
      "source": [
        "eval(pred,test_y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.83      0.31      0.45        16\n",
            "         1.0       0.54      0.93      0.68        14\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.69      0.62      0.57        30\n",
            "weighted avg       0.70      0.60      0.56        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgCaR2TPfoR"
      },
      "source": [
        "Condidering the small size of the sample we should perform a cross-validation to evaluate the model. We implemented a function to do this and we have the following result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pdKqpslZtFY",
        "outputId": "e4715583-f5ee-459c-a4f0-19ea0ce568f2"
      },
      "source": [
        "random.seed(2022)\n",
        "cross_validation_NBSVM(Apex_AD2600_Progressive_scan_DVD_player_x, \n",
        "                       Apex_AD2600_Progressive_scan_DVD_player_y,\n",
        "                       cv = 4,\n",
        "                       alpha = .1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnAMD_0Zd9lZ"
      },
      "source": [
        "This is not a very good result considering that this sample contains around 60% negative values. So a naive model (predicting always negative) would acheive the same accuracy. We think the small size of our sample is responsible for this outcome. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYbTxw2jdP2U",
        "outputId": "bafa6982-3703-44e3-956e-b90b60b2b8d7"
      },
      "source": [
        "nb_neg = len([i for i, value in enumerate(Apex_AD2600_Progressive_scan_DVD_player_y) if value == -1])\n",
        "nb_pos = len([i for i, value in enumerate(Apex_AD2600_Progressive_scan_DVD_player_y) if value == 1])\n",
        "nb_pos, nb_neg"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqBbB3lFX0F9"
      },
      "source": [
        "# 4. SVM\n",
        "In order to perform the SVM implementation we used the svm object of the package: sklearn. We need to transform our reviews into vectors of V once again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU3asmLrX2ph"
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(Apex_AD2600_Progressive_scan_DVD_player_x, \n",
        "                                                    Apex_AD2600_Progressive_scan_DVD_player_y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=2000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXtCEQ1_g7GQ"
      },
      "source": [
        "# We vectorize again train_x:\n",
        "V, F, vectorization = vectorize(Train_x_sample = train_x, ngrams=(1,2))\n",
        "# Since binarized = True always here.\n",
        "F = np.where(F > 0,1,0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juBUoqzAX5Sn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc0e1d5-8a7c-4c3c-93f4-74225e850db2"
      },
      "source": [
        "# We define and fit the model:\n",
        "clf = svm.LinearSVC()\n",
        "clf.fit(F.T, train_y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShJRhdvYhPpw",
        "outputId": "2e5ed3de-b6e9-4528-b40c-37435bb52006"
      },
      "source": [
        "# We transform test_x into a vector of \n",
        "sample = vectorization.transform(test_x).toarray().T\n",
        "# We predict the outcome of test_x:\n",
        "pred_svm = clf.predict(vectorization.transform(test_x))\n",
        "pred_svm"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
              "        1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
              "       -1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3HrcDtYh-XB",
        "outputId": "f6d2d1e5-97d9-4273-d4cb-f5a5b5016107"
      },
      "source": [
        "eval(pred_svm,test_y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.59      0.81      0.68        16\n",
            "         1.0       0.62      0.36      0.45        14\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.61      0.58      0.57        30\n",
            "weighted avg       0.61      0.60      0.58        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwItz8mvlWUA"
      },
      "source": [
        "Once again we implemented a function defining the model directly with an argument NB to be True if you want NBSVM and false otherwise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trxQdiS2lavH"
      },
      "source": [
        "clf = NB_SVM_fit_model(Train_x_sample = train_x,\n",
        "                       Train_y_sample = train_y,\n",
        "                       ngrams = (1,2),\n",
        "                       NB=False) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CTTuB1Cl9Jl",
        "outputId": "9d5641f8-3704-43d4-d87f-7b4f7b8c7874"
      },
      "source": [
        "# Then to predict we do as above:\n",
        "\n",
        "# We transform test_x into a vector of \n",
        "sample = vectorization.transform(test_x).toarray().T\n",
        "# We predict the outcome of test_x:\n",
        "pred_svm = clf.predict(vectorization.transform(test_x))\n",
        "pred_svm"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
              "        1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
              "       -1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWdCkHBhmOko",
        "outputId": "3de2784f-ec1c-45f8-e409-e957f6832994"
      },
      "source": [
        "eval(pred_svm,test_y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.59      0.81      0.68        16\n",
            "         1.0       0.62      0.36      0.45        14\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.61      0.58      0.57        30\n",
            "weighted avg       0.61      0.60      0.58        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su5LVcAlX3US"
      },
      "source": [
        "# 5. NBSVM\n",
        "The idea of NBSVM is to create a model equivalent to SVM but changing from $x = \\hat{F}$ to $x = \\hat{F} o \\hat{r}$ (elementwise product). Let us remind that F is a matrix of size :$ len($V$) * nb~of~reviews$ and that $\\hat{r}$ is the log count ratio so a vector of size len($V$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqVJBajmtML"
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(Apex_AD2600_Progressive_scan_DVD_player_x, \n",
        "                                                    Apex_AD2600_Progressive_scan_DVD_player_y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=2000)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrfmiFfkr3hm"
      },
      "source": [
        "# We vectorize again train_x:\n",
        "V, F, vectorization = vectorize(Train_x_sample = train_x, ngrams=(1,2))\n",
        "# Since binarized = True always here.\n",
        "F = np.where(F > 0,1,0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz2f10kosA3H",
        "outputId": "e101e96a-a6ce-45ef-ed1a-78db5d6fc447"
      },
      "source": [
        "# We compute R, the log count ratio (it is R hat here since we use F hat to compute it)\n",
        "R = get_R(alpha = 10, Train_y_sample = train_y, F = F)\n",
        "R"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0365331 ,  0.0365331 , -0.05877708, ...,  0.0365331 ,\n",
              "        0.0365331 ,  0.0365331 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ppKM2XxtQNH"
      },
      "source": [
        "We compute now the elementwise product of $\\hat{r}$ and $\\hat{F}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVhtkx4VsdgC",
        "outputId": "def3accc-2eb6-473a-b348-0ef7f6a47311"
      },
      "source": [
        "# We define first a matrix r with the same number of columns as F and with each \n",
        "# column equal to R.\n",
        "r = np.array([list(R),]*len(F[0]))\n",
        "r = r.transpose()\n",
        "r"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0365331 ,  0.0365331 ,  0.0365331 , ...,  0.0365331 ,\n",
              "         0.0365331 ,  0.0365331 ],\n",
              "       [ 0.0365331 ,  0.0365331 ,  0.0365331 , ...,  0.0365331 ,\n",
              "         0.0365331 ,  0.0365331 ],\n",
              "       [-0.05877708, -0.05877708, -0.05877708, ..., -0.05877708,\n",
              "        -0.05877708, -0.05877708],\n",
              "       ...,\n",
              "       [ 0.0365331 ,  0.0365331 ,  0.0365331 , ...,  0.0365331 ,\n",
              "         0.0365331 ,  0.0365331 ],\n",
              "       [ 0.0365331 ,  0.0365331 ,  0.0365331 , ...,  0.0365331 ,\n",
              "         0.0365331 ,  0.0365331 ],\n",
              "       [ 0.0365331 ,  0.0365331 ,  0.0365331 , ...,  0.0365331 ,\n",
              "         0.0365331 ,  0.0365331 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9IntMsVtfi3",
        "outputId": "8df99597-cd32-4457-9376-8077963deef6"
      },
      "source": [
        "# We do the elementwise produt of R and F.\n",
        "product = np.multiply(r,F)\n",
        "product"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.        , -0.        , -0.        , ..., -0.        ,\n",
              "        -0.05877708, -0.        ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1d_sMwSwaLz",
        "outputId": "03a6178d-e9eb-429d-9fac-77b570497754"
      },
      "source": [
        "# We define the model:\n",
        "clf = svm.LinearSVC()\n",
        "clf.fit(product.T, train_y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_XaE7a_wbRn",
        "outputId": "ace2d77f-be93-429d-926b-bdddea270f38"
      },
      "source": [
        "# Then to predict we do as above:\n",
        "\n",
        "# We transform test_x into a vector of \n",
        "sample = vectorization.transform(test_x).toarray().T\n",
        "# We predict the outcome of test_x:\n",
        "pred_nbsvm = clf.predict(vectorization.transform(test_x))\n",
        "pred_nbsvm"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
              "       -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
              "       -1., -1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYIHwUegw9_O",
        "outputId": "b29a3178-dd7c-4732-eec6-e4df95781171"
      },
      "source": [
        "eval(pred_nbsvm,test_y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.64      0.56      0.60        16\n",
            "         1.0       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.60      0.60      0.60        30\n",
            "weighted avg       0.61      0.60      0.60        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYzknPomxRLc"
      },
      "source": [
        "We can use the function implemented directly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp-GRVBxxXbG"
      },
      "source": [
        "clf = NB_SVM_fit_model(train_x, train_y, ngrams = (1,2), NB=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYwZmp_WyVk4",
        "outputId": "ac044808-b258-4c2e-8bae-cf35f22d2899"
      },
      "source": [
        "sample = vectorization.transform(test_x).toarray().T\n",
        "# We predict the outcome of test_x:\n",
        "pred_nbsvm = clf.predict(vectorization.transform(test_x))\n",
        "pred_nbsvm"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
              "       -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
              "       -1., -1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANUKV8mrybz1",
        "outputId": "028b748d-f711-4594-b6cf-524289f39123"
      },
      "source": [
        "eval(pred_nbsvm,test_y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.64      0.56      0.60        16\n",
            "         1.0       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.60      0.60      0.60        30\n",
            "weighted avg       0.61      0.60      0.60        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
