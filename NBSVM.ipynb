{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBSVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGhipDj6Ok9G7EToZIE5ML",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulBarriere/TSE-NBSVM/blob/main/NBSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dtwePdw1Tx5"
      },
      "source": [
        "# NBSVM Project\n",
        "\n",
        "Paul Barriere and Nicolas Le Gall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUWkXjGy4wf2"
      },
      "source": [
        "# Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.metrics import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs2P00Xn10jy"
      },
      "source": [
        "## I) Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6gPecpZ1TCq"
      },
      "source": [
        "# Example data : \n",
        "# The structure should be two list. Called train_x and train_y.\n",
        "# train_x should contain for each element the text (review).\n",
        "# train_y should contain 1 or -1 (1 means positive and -1 means negative).\n",
        "\n",
        "train_x = ['This canon is very bad, bad. Peace of shit!!', 'Perfect and even incredible for me!', 'Incredible pictures!']\n",
        "train_y = [-1,1,1]\n",
        "\n",
        "test_x = [\"It's very bad\", 'So super cool', 'Greatest of all time']\n",
        "test_y = [-1, 1, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OixO-8g5FfM3"
      },
      "source": [
        "## II) Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieqr0cRw5lbp"
      },
      "source": [
        "''' Function vectorize returns:\n",
        "        - the Vector V defined as the feature vector (ie a vector containing \n",
        "        strings which are the list of vocabulary)\n",
        "        \n",
        "        - the matrix F where the ith column is f(i) the feature count vector\n",
        "          for training case i as defined in the paper. F is therefore a matrix \n",
        "          of size : len(V) x len(train_x) (let's remind that V is the vocabulary \n",
        "          vector and that len(train_x) is the number of reviews in the training \n",
        "          example)\n",
        "\n",
        "          - vectorization which is the CountVectorizer fittid with the data. This\n",
        "          is used later to transform the test data.\n",
        "\n",
        "\n",
        "    Function vectorize uses:\n",
        "        - Train_x_sample: a list of strings (list of reviews)\n",
        "\n",
        "        - ngrams: a tupple with for example (1,1) meaning that you want only \n",
        "                  unigrams and (1,2) meaning that you want both unigrams and \n",
        "                  bigrams\n",
        "'''\n",
        "\n",
        "def vectorize(Train_x_sample, ngrams):\n",
        "  vectorization =  CountVectorizer(ngram_range = ngrams)\n",
        "  vectorization.fit(Train_x_sample)\n",
        "  V = vectorization.get_feature_names()\n",
        "  \n",
        "  F = vectorization.transform(Train_x_sample)\n",
        "  F = F.toarray().T\n",
        "\n",
        "  return V, F, vectorization\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''' Function get_P returns:\n",
        "        - the Vector P as defined is the paper. This vector is the sum of two\n",
        "        element: alpha a smoothing parameter and the sum of f(i) for all i where \n",
        "        the review is positive (ie we the reviews where train_y = 1 and sum the\n",
        "        columns of the matrix F. )\n",
        "  \n",
        "    Function vectorize uses:\n",
        "        - alpha a real number between 0 and 1\n",
        "        \n",
        "        - Train_y_sample which is the value of a review (positive / negative) of\n",
        "        the training dataset. \n",
        "\n",
        "        - The matrix F\n",
        "'''\n",
        "\n",
        "def get_P(alpha, Train_y_sample, F):\n",
        "  pos_list = [i for i, value in enumerate(Train_y_sample) if value == 1]\n",
        "  restrict_F = F[:,pos_list]\n",
        "  P = alpha + np.sum(restrict_F, axis = 1)\n",
        "  return P\n",
        "\n",
        "\n",
        "''' Function get_Q returns:\n",
        "        - the Vector Q as defined is the paper. This vector is the sum of two\n",
        "        element: alpha a smoothing parameter and the sum of f(i) for all i where \n",
        "        the review is negative (ie we the reviews where train_y = -1 and sum the\n",
        "        columns of the matrix F. )\n",
        "  \n",
        "    Function vectorize uses:\n",
        "        - alpha a real number between 0 and 1\n",
        "        \n",
        "        - Train_y_sample which is the value of a review (positive / negative) of\n",
        "        the training dataset. \n",
        "\n",
        "        - The matrix F\n",
        "'''\n",
        "\n",
        "def get_Q(alpha, Train_y_sample, F):\n",
        "  neg_list = [i for i, value in enumerate(Train_y_sample) if value == 0]\n",
        "  restrict_F = F[:,neg_list]\n",
        "  Q = alpha + np.sum(restrict_F, axis = 1)\n",
        "  return Q\n",
        "\n",
        "\n",
        "''' Function get_r returns:\n",
        "        - the vector r which is the log-count ratio defined in the paper. \n",
        "\n",
        "    Function get_r uses: \n",
        "        - functions get_P and get_Q as defined above\n",
        "\n",
        "        - alpha a real number between 0 and 1\n",
        "        \n",
        "        - Train_y_sample which is the value of a review (positive / negative) of\n",
        "        the training dataset. \n",
        "\n",
        "        - The matrix F\n",
        "'''\n",
        "\n",
        "def get_R(alpha, Train_y_sample, F):\n",
        "  P = get_P(alpha, Train_y_sample, F)\n",
        "  Q = get_Q(alpha, Train_y_sample, F)\n",
        "  \n",
        "  P = P / np.linalg.norm(P,ord=2)\n",
        "  Q = Q / np.linalg.norm(Q,ord=2)\n",
        "  R = np.log(P/Q)\n",
        "\n",
        "  return R\n",
        "\n",
        "\n",
        "\n",
        "''' --------------------------------------------------------------------------\n",
        "Multinomial Naive Bayes (MNB)\n",
        "\n",
        "Function MNB_fit_model returns:\n",
        "        - W as defined in the paper. In this case W is R. So the function\n",
        "        compute R.\n",
        "\n",
        "        - X as defined in the paper. Here it is f or ^f (depending on what you \n",
        "        choose)\n",
        "\n",
        "        - B as defined in the paper (log(N+/N-))\n",
        "\n",
        "Function MNB_fit_model uses:\n",
        "        - Train_x_sample: a list of strings (list of reviews)\n",
        "\n",
        "        - Train_y_sample which is the value of a review (positive / negative) of\n",
        "        the training dataset. \n",
        "\n",
        "        - ngrams : a tupple of two integer. \n",
        "\n",
        "        - alpha : smoothing parameter\n",
        "\n",
        "        - binarized : a boolean parameter. If TRUE then we tranform F (and p,q,\n",
        "        r) by taking for each element of F 1 if it is strictly positive and 0 \n",
        "        otherwise. \n",
        "\n",
        "'''\n",
        "\n",
        "def MNB_fit_model(Train_x_sample, Train_y_sample, \n",
        "                  ngrams, alpha = 1, binarized=False):\n",
        "  # Define V and F\n",
        "  V,F, vectorization = vectorize(Train_x_sample, ngrams)\n",
        "\n",
        "\n",
        "  # We change F if Binarized == TRUE:\n",
        "  if binarized == True:\n",
        "    F = np.where(F > 0,1,0)\n",
        "\n",
        "  # Define R and so W:\n",
        "  R = get_R(alpha, Train_y_sample, F)\n",
        "  W = R\n",
        "\n",
        "  # Compute B:\n",
        "  nb_neg = len([i for i, value in enumerate(Train_y_sample) if value == -1])\n",
        "  nb_pos = len([i for i, value in enumerate(Train_y_sample) if value == 1])\n",
        "  B = np.log(nb_pos/nb_neg)\n",
        "\n",
        "  return W, B, binarized, vectorization\n",
        "\n",
        "\n",
        "''' Function predict returns:\n",
        "        - Preds a vector of predictions containing -1 or 1. \n",
        "\n",
        "Function predict uses:\n",
        "        - sample: a list of strings (list of reviews) on which to predict if it \n",
        "        is a positive or negative review. \n",
        "\n",
        "        - the parameters found in the fitting (binarized,W,B)\n",
        "\n",
        "The aim is to use this function for all cases MNB, SVM and NBSVM\n",
        "\n",
        "'''\n",
        "\n",
        "def predict(binarized,W,B,vectorization,sample):\n",
        "  # Transform the sample in term of V:\n",
        "  sample = vectorization.transform(sample).toarray().T\n",
        "\n",
        "  # Compute the prediction\n",
        "  predictions =  np.sign(np.dot(W.T, sample) + B)\n",
        "  return predictions\n",
        "\n",
        "''' Function eval returns:\n",
        "        - a vector containing the accuracy, precision, recall and F1 score.\n",
        "\n",
        "Function eval uses:\n",
        "        - predictions: a list of integer equals to 1 or -1. \n",
        "\n",
        "        - true_value: a list of integers equals to 1 or -1. \n",
        "\n",
        "The aim is to use this function for all cases MNB, SVM and NBSVM\n",
        "\n",
        "'''\n",
        "\n",
        "def eval(predictions, y_test):\n",
        "  print('accuracy {}'.format(accuracy_score(y_test, predictions)))\n",
        "  print(classification_report(y_test, predictions))\n",
        "  return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIxLrZmUCF0o",
        "outputId": "4c0dfdd7-e6f6-487a-a90b-20913e183ac0"
      },
      "source": [
        "''' Illustration on this example with first 10 elements of vector V '''\n",
        "V = vectorize(train_x, (1,2))[0]\n",
        "V[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and',\n",
              " 'and even',\n",
              " 'bad',\n",
              " 'bad bad',\n",
              " 'bad peace',\n",
              " 'canon',\n",
              " 'canon is',\n",
              " 'even',\n",
              " 'even incredible',\n",
              " 'for']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT2W-9x-OAFr",
        "outputId": "c52e9840-9f91-46b4-a515-24e52a567d71"
      },
      "source": [
        "''' Illustration on this example with first two columns of the matrix F (ie the \n",
        "two first reviews and it's 10 first lines (ie 10 first element of V) '''\n",
        "F = vectorize(train_x, (1,2))[1]\n",
        "F[:10,:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 1],\n",
              "       [2, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPvT0ZL0jxMq",
        "outputId": "61154d52-7eb6-405b-cef6-d048d93280c1"
      },
      "source": [
        "get_R(1,train_y, F)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.23156537,  0.23156537, -0.46158181, -0.46158181, -0.46158181,\n",
              "       -0.46158181, -0.46158181,  0.23156537,  0.23156537,  0.23156537,\n",
              "        0.23156537,  0.63703048,  0.23156537,  0.23156537, -0.46158181,\n",
              "       -0.46158181,  0.23156537, -0.46158181, -0.46158181, -0.46158181,\n",
              "       -0.46158181,  0.23156537,  0.23156537,  0.23156537, -0.46158181,\n",
              "       -0.46158181, -0.46158181, -0.46158181, -0.46158181])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8FKM-YNFat1"
      },
      "source": [
        "## III) Naive bayes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOtQ10YHfCRy"
      },
      "source": [
        "W, B, binarized, vectorization = MNB_fit_model(Train_x_sample = train_x, \n",
        "                                              Train_y_sample = train_y,\n",
        "                                              ngrams = (1,2), \n",
        "                                              alpha = 1, \n",
        "                                              binarized=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6RKZ48ZScim",
        "outputId": "d4f4787d-e5b4-4fc9-e16e-4e5bfd339bdc"
      },
      "source": [
        "pred = predict(binarized,W,B,vectorization,test_x)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.,  1.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmZdlykqYnNQ",
        "outputId": "3f7a0d04-79b5-4d7c-956c-e5beeaf95429"
      },
      "source": [
        "eval(pred,test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHXoPUPBd42z"
      },
      "source": [
        "# IV) SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrsGITDPd76Q",
        "outputId": "4ba83265-8f31-40a9-99a4-dae3bbb90da1"
      },
      "source": [
        "clf = svm.LinearSVC()\n",
        "clf.fit(F.T, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4O5GJdSgY_J",
        "outputId": "078340cb-6b90-43b4-e80b-3354f2163afd"
      },
      "source": [
        "pred_svm = clf.predict(vectorization.transform(test_x))\n",
        "pred_svm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxCiu7dfg_Ax",
        "outputId": "776c07d7-c6bd-48c7-c39c-b8f80e505c7f"
      },
      "source": [
        "eval(pred_svm,test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q5bpBuzhG4C"
      },
      "source": [
        "# V) NBSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "e2bekAevhJ04",
        "outputId": "be0bbeb3-8581-4217-b33d-3bd8b79b0fe4"
      },
      "source": [
        "clf = svm.LinearSVC()\n",
        "clf.fit(np.dot(get_R(1,train_y, F),F), train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-1c780e0c4214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_R\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m    234\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-7.84689069  2.95268423  1.10016123].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    }
  ]
}